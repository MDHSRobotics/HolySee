# MSee Configuration
# Use this file to define how to identify cameras and other related devices, e.g. lidars
# Also specify image processing components
# AR stands for Augmented Reality filters
# CV stands for Computer Vision sinks
# the argument specifies the name of the component to use

# The format is:
# <instance name>.<device name>.<field> = <value>
#
# intance name - each instance of MSee is given a name.  In this case, this instance is called Tegra.  This is to enable multiple CV co-processors to be added concurrently into a robot.
# device name - each device is given a name.  In this case, three device are identified for this instance.  
# fields - each device can have multiple configuration entries. Each device should have 
#           1) identifier entry.  The identifier entry is used to identify the specific device.  V4l2--ctl is used to identify video devices.  a custom script is used to identify USB devices
#           2) AR entries specify are used to specify which Augmented Reality filter component to use for the specified device
#           3) CV entries specify are used to specify which Computer Vision sink component to use for the specified device
#			4) source entries specify the source element to use for a video source.  The default is v4l2src.  This is optional.  The tegra should use source nvcamerasrc.



Tegra.tegraCam.identifier = vi-output-2, ov5693 6-0036
Tegra.tegraCam.AR = steamAR
#Tegra.tegraCam.AR = gearAR
Tegra.tegraCam.source = nvcamerasrc fpsRange="30 30" ! video/x-raw\(memory:NVMM\), width=\(int\)640, height=\(int\)480, format=\(string\)I420, framerate=\(fraction\)30/1 ! nvvidconv flip-method=2

Tegra.zed.identifier = Zebra CAMERA
#Tegra.zed.AR = squareAR
#Tegra.zed.CV = zedCV

Tegra.lidar.identifier = Logitech_USB_Receiver
#Tegra.lidar.AR = squareAR
#Tegra.lidar.CV = lidarCV